{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Í∏∞Î≥∏ train ÌååÏùº Ìò∏Ï∂ú\n",
    "- Í∏∞Î≥∏Ï†ÅÏù∏ train ÌååÏùºÏùò ÏÑ±Îä•ÏùÑ ÌôïÏù∏ÌïòÍ∏∞ ÏúÑÌï¥ Ï†úÏûë. \n",
    "- test_pearson() score: 0.81\n",
    "- base, 80% Ï¶ùÍ∞Ä, MSE score, 3 times: 0.9\n",
    "- Ï∂îÍ∞Ä 500 step warmup: 0.91"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'0.8, base'   code   lightning_logs   output.csv     wandb\n",
      " Readme.md    data   model.pt\t      output_1.csv\n",
      "Namespace(batch_size=16, dev_path='./data/dev.csv', entity_name='nlp-10', learning_rate=1e-05, max_epoch=3, model_name='klue/roberta-small', predict_path='./data/test.csv', project_name='sts', shuffle=True, sweeps_cnt='1', test_path='./data/dev.csv', train='True', train_path='./data/train.csv')\n",
      "Train mode\n",
      "Create sweep with ID: kye60lq5\n",
      "Sweep URL: https://wandb.ai/nlp-10/sts/sweeps/kye60lq5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f4p61e0z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkms7530\u001b[0m (\u001b[33mnlp-10\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/opt/ml/wandb/run-20230414_064359-f4p61e0z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdazzling-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/nlp-10/sts\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/nlp-10/sts/sweeps/kye60lq5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/nlp-10/sts/runs/f4p61e0z\u001b[0m\n",
      "Global seed set to 10\n",
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16783/16783 [00:06<00:00, 2511.49it/s]\n",
      "tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 550/550 [00:00<00:00, 2587.39it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                             | Params\n",
      "---------------------------------------------------------------\n",
      "0 | plm       | RobertaForSequenceClassification | 68.1 M\n",
      "1 | loss_func | MSELoss                          | 0     \n",
      "---------------------------------------------------------------\n",
      "68.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "68.1 M    Total params\n",
      "272.367   Total estimated model params size (MB)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr' was locked by 'sweep' (ignored update).\n",
      "Sanity Checking: 0it [00:00, ?it/s]/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1049/1049 [04:20<00:00,  4.03it/s, v_num=1e0z]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|‚ñå                  | 1/35 [00:00<00:00, 94.97it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|‚ñà                  | 2/35 [00:00<00:00, 89.49it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|‚ñà‚ñã                 | 3/35 [00:00<00:00, 87.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|‚ñà‚ñà‚ñè                | 4/35 [00:00<00:00, 86.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|‚ñà‚ñà‚ñã                | 5/35 [00:00<00:00, 88.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|‚ñà‚ñà‚ñà‚ñé               | 6/35 [00:00<00:00, 72.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|‚ñà‚ñà‚ñà‚ñä               | 7/35 [00:00<00:00, 43.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|‚ñà‚ñà‚ñà‚ñà‚ñé              | 8/35 [00:00<00:00, 33.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|‚ñà‚ñà‚ñà‚ñà‚ñâ              | 9/35 [00:00<00:00, 28.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 10/35 [00:00<00:00, 25.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 11/35 [00:00<00:01, 23.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 12/35 [00:00<00:01, 22.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 13/35 [00:00<00:01, 20.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 14/35 [00:00<00:01, 20.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 15/35 [00:00<00:01, 19.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 16/35 [00:00<00:01, 18.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 17/35 [00:00<00:00, 18.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 18/35 [00:01<00:00, 17.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 19/35 [00:01<00:00, 17.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 20/35 [00:01<00:00, 17.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 21/35 [00:01<00:00, 16.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 22/35 [00:01<00:00, 16.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 23/35 [00:01<00:00, 16.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 24/35 [00:01<00:00, 16.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 25/35 [00:01<00:00, 16.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 26/35 [00:01<00:00, 15.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 27/35 [00:01<00:00, 15.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 28/35 [00:01<00:00, 15.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 29/35 [00:01<00:00, 15.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 30/35 [00:01<00:00, 15.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 31/35 [00:02<00:00, 15.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 32/35 [00:02<00:00, 15.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 33/35 [00:02<00:00, 15.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 34/35 [00:02<00:00, 15.16it/s]\u001b[A\n",
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1049/1049 [04:22<00:00,  3.99it/s, v_num=1e0z]\u001b[A\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1049/1049 [04:21<00:00,  4.01it/s, v_num=1e0z]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|‚ñå                 | 1/35 [00:00<00:00, 109.37it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|‚ñà                 | 2/35 [00:00<00:00, 102.63it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|‚ñà‚ñå                | 3/35 [00:00<00:00, 101.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|‚ñà‚ñà                | 4/35 [00:00<00:00, 100.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|‚ñà‚ñà‚ñã                | 5/35 [00:00<00:00, 99.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|‚ñà‚ñà‚ñà‚ñé               | 6/35 [00:00<00:00, 73.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|‚ñà‚ñà‚ñà‚ñä               | 7/35 [00:00<00:00, 43.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|‚ñà‚ñà‚ñà‚ñà‚ñé              | 8/35 [00:00<00:00, 33.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|‚ñà‚ñà‚ñà‚ñà‚ñâ              | 9/35 [00:00<00:00, 28.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 10/35 [00:00<00:00, 25.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 11/35 [00:00<00:01, 23.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 12/35 [00:00<00:01, 21.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 13/35 [00:00<00:01, 20.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 14/35 [00:00<00:01, 19.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 15/35 [00:00<00:01, 19.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 16/35 [00:00<00:01, 18.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 17/35 [00:00<00:00, 18.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 18/35 [00:01<00:00, 17.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 19/35 [00:01<00:00, 17.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 20/35 [00:01<00:00, 17.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 21/35 [00:01<00:00, 16.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 22/35 [00:01<00:00, 16.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 23/35 [00:01<00:00, 16.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 24/35 [00:01<00:00, 16.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 25/35 [00:01<00:00, 16.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 27/35 [00:01<00:00, 15.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 28/35 [00:01<00:00, 15.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 29/35 [00:01<00:00, 15.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 30/35 [00:01<00:00, 15.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 31/35 [00:02<00:00, 15.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 32/35 [00:02<00:00, 15.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 33/35 [00:02<00:00, 15.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 34/35 [00:02<00:00, 15.14it/s]\u001b[A\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1049/1049 [04:24<00:00,  3.97it/s, v_num=1e0z]\u001b[A\n",
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1049/1049 [04:21<00:00,  4.02it/s, v_num=1e0z]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|‚ñå                  | 1/35 [00:00<00:00, 99.24it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|‚ñà                  | 2/35 [00:00<00:00, 95.77it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|‚ñà‚ñã                 | 3/35 [00:00<00:00, 96.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|‚ñà‚ñà‚ñè                | 4/35 [00:00<00:00, 96.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|‚ñà‚ñà‚ñã                | 5/35 [00:00<00:00, 96.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|‚ñà‚ñà‚ñà‚ñé               | 6/35 [00:00<00:00, 72.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|‚ñà‚ñà‚ñà‚ñä               | 7/35 [00:00<00:00, 43.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|‚ñà‚ñà‚ñà‚ñà‚ñé              | 8/35 [00:00<00:00, 33.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|‚ñà‚ñà‚ñà‚ñà‚ñâ              | 9/35 [00:00<00:00, 28.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 10/35 [00:00<00:00, 25.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 11/35 [00:00<00:01, 23.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 12/35 [00:00<00:01, 21.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 13/35 [00:00<00:01, 20.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 14/35 [00:00<00:01, 19.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 15/35 [00:00<00:01, 19.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 16/35 [00:00<00:01, 18.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 17/35 [00:00<00:00, 18.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 18/35 [00:01<00:00, 17.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 19/35 [00:01<00:00, 17.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 20/35 [00:01<00:00, 17.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 21/35 [00:01<00:00, 16.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 22/35 [00:01<00:00, 16.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 23/35 [00:01<00:00, 16.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 24/35 [00:01<00:00, 16.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 25/35 [00:01<00:00, 16.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 26/35 [00:01<00:00, 15.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 27/35 [00:01<00:00, 15.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 28/35 [00:01<00:00, 15.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 29/35 [00:01<00:00, 15.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 30/35 [00:01<00:00, 15.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 31/35 [00:02<00:00, 15.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 32/35 [00:02<00:00, 15.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 33/35 [00:02<00:00, 15.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 34/35 [00:02<00:00, 15.12it/s]\u001b[A\n",
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1049/1049 [04:23<00:00,  3.98it/s, v_num=1e0z]\u001b[A\n",
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1049/1049 [04:23<00:00,  3.98it/s, v_num=1e0z]\u001b[A`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1049/1049 [04:25<00:00,  3.94it/s, v_num=1e0z]\n",
      "tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 550/550 [00:00<00:00, 2840.86it/s]\n",
      "tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1100/1100 [00:00<00:00, 2791.11it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr' was locked by 'sweep' (ignored update).\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Testing DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:02<00:00, 13.15it/s]\n",
      "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
      "‚îÉ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
      "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
      "‚îÇ\u001b[36m \u001b[0m\u001b[36m      test_pearson       \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.7843421101570129    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_pearson ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss ‚ñà‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_pearson ‚ñÅ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_pearson 0.78434\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train_loss 0.61982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step 3147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss 0.91343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_pearson 0.78434\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mdazzling-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/nlp-10/sts/runs/f4p61e0z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230414_064359-f4p61e0z/logs\u001b[0m\n",
      "Run f4p61e0z errored: RuntimeError('Parent directory model_klue does not exist.')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run f4p61e0z errored: RuntimeError('Parent directory model_klue does not exist.')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 50h7psep with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/opt/ml/wandb/run-20230414_065744-50h7psep\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msummer-sweep-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/nlp-10/sts\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/nlp-10/sts/sweeps/kye60lq5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/nlp-10/sts/runs/50h7psep\u001b[0m\n",
      "Global seed set to 10\n",
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16783/16783 [00:05<00:00, 2861.85it/s]\n",
      "tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 550/550 [00:00<00:00, 2902.90it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                             | Params\n",
      "---------------------------------------------------------------\n",
      "0 | plm       | RobertaForSequenceClassification | 68.1 M\n",
      "1 | loss_func | MSELoss                          | 0     \n",
      "---------------------------------------------------------------\n",
      "68.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "68.1 M    Total params\n",
      "272.367   Total estimated model params size (MB)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr' was locked by 'sweep' (ignored update).\n",
      "Sanity Checking: 0it [00:00, ?it/s]/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 973/1049 [04:02<00:18,  4.01it/s, v_num=psep]"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!python code/base_model/base_2.py --train=True --model_name=\"klue/roberta-small\" --sweeps_cnt=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'0.8, base'   code   lightning_logs   output.csv     wandb\n",
      " Readme.md    data   model.pt\t      output_1.csv\n",
      "Namespace(batch_size=16, dev_path='./data/dev.csv', learning_rate=1e-05, max_epoch=3, model_name='klue/roberta-base', predict_path='./data/test.csv', project_name='', shuffle=True, test_path='./data/dev.csv', train=False, train_path='./data/train.csv')\n",
      "Inference mode\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 550/550 [00:00<00:00, 2819.78it/s]\n",
      "tokenizing-idx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 550/550 [00:00<00:00, 828021.25it/s]\n",
      "tokenizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1100/1100 [00:00<00:00, 2885.46it/s]\n",
      "tokenizing-idx: 0it [00:00, ?it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, predict_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Predicting DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [00:11<00:00,  6.04it/s]\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!python code/base_model/base_2.py --train=False --model_name=\"klue/roberta-base\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
